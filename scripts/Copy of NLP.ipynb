{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1VEhHiD2-ZzZ-RtME2pnEPL0Fhl2wtKii","timestamp":1764770864233}],"gpuType":"T4","authorship_tag":"ABX9TyN8mGEYt6Md2JFNU9DsLrQD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"xQjxvouTTeot","executionInfo":{"status":"ok","timestamp":1764768186886,"user_tz":-330,"elapsed":4198,"user":{"displayName":"Nikita V","userId":"13064955447044106141"}},"outputId":"86ffa2bc-8f25-4e61-a6e2-58eda9798723"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n","Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n","Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n","Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}],"source":["!pip install transformers datasets librosa soundfile numpy\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NUFWVgf8TwAz","executionInfo":{"status":"ok","timestamp":1764768194169,"user_tz":-330,"elapsed":4732,"user":{"displayName":"Nikita V","userId":"13064955447044106141"}},"outputId":"62843701-da3b-4051-d188-03254c91215a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["PROJECT_DIR = \"/content/drive/MyDrive/Projects/IntelligentSpeechTherapy_NLP\"\n","\n","DATA_DIR = f\"{PROJECT_DIR}/data\"\n","REFERENCE_AUDIO_DIR = f\"{DATA_DIR}/reference_audio\"\n","PHONEME_AUDIO_DIR = f\"{REFERENCE_AUDIO_DIR}/phonemes\"\n","PHONEME_METADATA = f\"{PROJECT_DIR}/metadata/phoneme_audio_index.json\"\n","\n","print(\"Project folder:\", PROJECT_DIR)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S86Q0UQHT50x","executionInfo":{"status":"ok","timestamp":1764768435411,"user_tz":-330,"elapsed":26,"user":{"displayName":"Nikita V","userId":"13064955447044106141"}},"outputId":"9d3155c4-ce27-460e-a0e2-030fb74bfee6"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Project folder: /content/drive/MyDrive/Projects/IntelligentSpeechTherapy_NLP\n"]}]},{"cell_type":"code","source":["import torch, numpy as np, soundfile as sf, os, json\n","import torchaudio\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using device:\", DEVICE)\n","\n","# Load torchaudio's wav2vec2 base model\n","bundle = torchaudio.pipelines.WAV2VEC2_BASE\n","model = bundle.get_model().to(DEVICE)\n","model.eval()\n","\n","print(\"Loaded torchaudio bundle: WAV2VEC2_BASE\")\n","\n","# helpers\n","def load_audio_as_array(path, target_sr=16000):\n","    data, sr = sf.read(path, dtype='float32')\n","    if sr != target_sr:\n","        import librosa\n","        data = librosa.resample(data, sr, target_sr)\n","        sr = target_sr\n","    if data.ndim > 1:\n","        data = data.mean(axis=1)\n","    return data, sr\n","\n","def wav2vec_embedding_torchaudio(audio_array, sr=16000):\n","    tensor = torch.from_numpy(audio_array).float().to(DEVICE)\n","    if tensor.dim() == 1:\n","        tensor = tensor.unsqueeze(0)\n","\n","    with torch.no_grad():\n","        features, _ = model.extract_features(tensor)\n","        last = features[-1]               # [1, T, D]\n","        emb = last.mean(dim=1).squeeze()  # (D,)\n","        return emb.cpu().numpy()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KStill6OYtp4","executionInfo":{"status":"ok","timestamp":1764768288248,"user_tz":-330,"elapsed":1013,"user":{"displayName":"Nikita V","userId":"13064955447044106141"}},"outputId":"3838ca68-66df-4acc-ecc4-4bd6152652d0"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Loaded torchaudio bundle: WAV2VEC2_BASE\n"]}]},{"cell_type":"code","source":["files = sorted([f for f in os.listdir(PHONEME_DIR) if f.lower().endswith(\".wav\")])\n","print(\"Processing\", len(files), \"files\")\n","\n","embeddings = []\n","index_map = {}\n","\n","for i, fname in enumerate(files):\n","    phoneme = os.path.splitext(fname)[0]\n","    path = os.path.join(PHONEME_DIR, fname)\n","    print(f\"[{i+1}/{len(files)}] {phoneme}\")\n","    audio, sr = load_audio_as_array(path, target_sr=16000)\n","    emb = wav2vec_embedding_torchaudio(audio, sr=sr)\n","    embeddings.append(emb)\n","    index_map[phoneme] = i\n","    # optional: save per-phoneme numpy\n","    np.save(os.path.join(OUT_MODELS, f\"{phoneme}.npy\"), emb)\n","\n","emb_matrix = np.stack(embeddings, axis=0)  # (N, D)\n","OUT_EMB = os.path.join(META_DIR, \"phoneme_embeddings.npy\")\n","OUT_IDX = os.path.join(META_DIR, \"phoneme_embeddings_index.json\")\n","\n","np.save(OUT_EMB, emb_matrix)\n","with open(OUT_IDX, \"w\") as f:\n","    json.dump(index_map, f, indent=2)\n","\n","print(\"Saved embeddings matrix to:\", OUT_EMB)\n","print(\"Saved index map to:\", OUT_IDX)\n","print(\"Embeddings shape:\", emb_matrix.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p8r8RyKBZsE5","executionInfo":{"status":"ok","timestamp":1764768827681,"user_tz":-330,"elapsed":23452,"user":{"displayName":"Nikita V","userId":"13064955447044106141"}},"outputId":"f5950da5-c712-4d18-c25e-fb14913503a6"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 42 files\n","[1/42] AA1\n","[2/42] AE1\n","[3/42] AH0\n","[4/42] AH1\n","[5/42] AO1\n","[6/42] AW1\n","[7/42] AY1\n","[8/42] B\n","[9/42] CH\n","[10/42] D\n","[11/42] DH\n","[12/42] EH0\n","[13/42] EH1\n","[14/42] ER0\n","[15/42] ER1\n","[16/42] F\n","[17/42] G\n","[18/42] HH\n","[19/42] IH0\n","[20/42] IH1\n","[21/42] IY0\n","[22/42] IY1\n","[23/42] JH\n","[24/42] K\n","[25/42] L\n","[26/42] M\n","[27/42] N\n","[28/42] NG\n","[29/42] OY1\n","[30/42] P\n","[31/42] R\n","[32/42] S\n","[33/42] SH\n","[34/42] T\n","[35/42] TH\n","[36/42] UH1\n","[37/42] UW1\n","[38/42] V\n","[39/42] W\n","[40/42] Y\n","[41/42] Z\n","[42/42] ZH\n","Saved embeddings matrix to: /content/drive/MyDrive/Projects/IntelligentSpeechTherapy_NLP/metadata/phoneme_embeddings.npy\n","Saved index map to: /content/drive/MyDrive/Projects/IntelligentSpeechTherapy_NLP/metadata/phoneme_embeddings_index.json\n","Embeddings shape: (42, 768)\n"]}]},{"cell_type":"code","source":["EMB = np.load(OUT_EMB)\n","with open(OUT_IDX) as f:\n","    idx = json.load(f)\n","print(\"Loaded embedding matrix:\", EMB.shape)\n","print(\"Number of phonemes in index:\", len(idx))\n","\n","# Print sample norms\n","for k in list(idx.keys())[:6]:\n","    i = idx[k]\n","    vec = EMB[i]\n","    print(k, \"-> index\", i, \", norm=\", round(np.linalg.norm(vec), 3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yILMpse9bBwT","executionInfo":{"status":"ok","timestamp":1764768884668,"user_tz":-330,"elapsed":12,"user":{"displayName":"Nikita V","userId":"13064955447044106141"}},"outputId":"5feafa3f-0c35-442f-d4a0-0a893eca1923"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded embedding matrix: (42, 768)\n","Number of phonemes in index: 42\n","AA1 -> index 0 , norm= 7.155\n","AE1 -> index 1 , norm= 7.587\n","AH0 -> index 2 , norm= 7.68\n","AH1 -> index 3 , norm= 7.79\n","AO1 -> index 4 , norm= 7.127\n","AW1 -> index 5 , norm= 7.578\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(OUT_EMB)\n","files.download(OUT_IDX)\n","\n","# Zip per-phoneme .npy files for download\n","import shutil\n","shzip = os.path.join(OUT_MODELS, \"phoneme_npy.zip\")\n","shutil.make_archive(shzip.replace(\".zip\",\"\"), 'zip', OUT_MODELS)\n","files.download(shzip)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"HwKSddnRbERd","outputId":"35b65fb3-dc0c-4288-d6be-47a49f80e472"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_fd387178-3f25-4748-81c0-c1eaaadb706f\", \"phoneme_embeddings.npy\", 129152)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_95ea4b0c-2eeb-44ce-af8b-7eb2259221d3\", \"phoneme_embeddings_index.json\", 498)"]},"metadata":{}}]},{"cell_type":"code","source":["import numpy as np\n","\n","v = np.load(\"/content/drive/MyDrive/Projects/IntelligentSpeechTherapy_NLP/models/embeddings/AH0.npy\")\n","print(\"Shape:\", v.shape)\n","print(\"Norm:\", np.linalg.norm(v))\n","print(\"First 5 values:\", v[:5])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDXiCAuucQLQ","executionInfo":{"status":"ok","timestamp":1764769260336,"user_tz":-330,"elapsed":19878,"user":{"displayName":"Nikita V","userId":"13064955447044106141"}},"outputId":"82371375-7836-4a5c-b7db-5e0e872390d1"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape: (768,)\n","Norm: 7.6802974\n","First 5 values: [ 0.42316183  0.37638757 -0.02638518  0.20448925  0.27085596]\n"]}]}]}